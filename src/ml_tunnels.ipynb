{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145d7a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, RepeatedKFold, LeaveOneOut\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import HuberRegressor, LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np, seaborn as sns, matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Add project root to path (for Jupyter notebooks)\n",
    "# Get the current directory and navigate to project root\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "from src.config import Config\n",
    "import src.eda as eda\n",
    "import src.present_value as present_value\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3754b750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Code\\Road-Project-Prediction\\src\\eda.py:292: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  w = (df[cols] / totals).fillna(0)\n"
     ]
    }
   ],
   "source": [
    "## FROM DATABASE\n",
    "pv = present_value.PresentValue()\n",
    "anual_increment = pv.fetch_incremento_from_database()\n",
    "\n",
    "fase = \"III\"\n",
    "preproccesing = eda.EDA()\n",
    "df_raw = preproccesing.assemble_projects_from_database(fase)\n",
    "df_vp = preproccesing.create_dataset(pv.present_value_costs, fase=fase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff83138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOMBRE DEL PROYECTO</th>\n",
       "      <th>CÓDIGO</th>\n",
       "      <th>LONGITUD KM</th>\n",
       "      <th>PUENTES VEHICULARES UND</th>\n",
       "      <th>PUENTES VEHICULARES M2</th>\n",
       "      <th>PUENTES PEATONALES UND</th>\n",
       "      <th>PUENTES PEATONALES M2</th>\n",
       "      <th>TUNELES UND</th>\n",
       "      <th>TUNELES KM</th>\n",
       "      <th>ALCANCE</th>\n",
       "      <th>...</th>\n",
       "      <th>7 - SOCAVACIÓN</th>\n",
       "      <th>8 - ESTRUCTURAS</th>\n",
       "      <th>9 - TÚNELES</th>\n",
       "      <th>10 - URBANISMO Y PAISAJISMO</th>\n",
       "      <th>11 - PREDIAL</th>\n",
       "      <th>12 - IMPACTO AMBIENTAL</th>\n",
       "      <th>13 - CANTIDADES</th>\n",
       "      <th>14 - EVALUACIÓN SOCIOECONÓMICA</th>\n",
       "      <th>15 - OTROS - MANEJO DE REDES</th>\n",
       "      <th>16 - DIRECCIÓN Y COORDINACIÓN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TERMINACIÓN TÚNEL DE LA LÍNEA</td>\n",
       "      <td>0347801</td>\n",
       "      <td>8.35</td>\n",
       "      <td>10</td>\n",
       "      <td>24258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>Rehabilitación</td>\n",
       "      <td>...</td>\n",
       "      <td>6.284023e+07</td>\n",
       "      <td>4.415680e+08</td>\n",
       "      <td>6.644646e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.663940e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.006346e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TERMINACIÓN TÚNEL DE LA LÍNEA</td>\n",
       "      <td>0347801</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.6000</td>\n",
       "      <td>Rehabilitación</td>\n",
       "      <td>...</td>\n",
       "      <td>6.472167e+07</td>\n",
       "      <td>4.547886e+08</td>\n",
       "      <td>1.632824e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.713759e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.066416e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TERMINACIÓN TÚNEL DE LA LÍNEA</td>\n",
       "      <td>0347801</td>\n",
       "      <td>8.50</td>\n",
       "      <td>16</td>\n",
       "      <td>26811</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2.2747</td>\n",
       "      <td>Rehabilitación</td>\n",
       "      <td>...</td>\n",
       "      <td>6.396909e+07</td>\n",
       "      <td>4.495003e+08</td>\n",
       "      <td>1.906902e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.693831e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.042388e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              NOMBRE DEL PROYECTO   CÓDIGO  LONGITUD KM  \\\n",
       "20  TERMINACIÓN TÚNEL DE LA LÍNEA  0347801         8.35   \n",
       "21  TERMINACIÓN TÚNEL DE LA LÍNEA  0347801         8.60   \n",
       "22  TERMINACIÓN TÚNEL DE LA LÍNEA  0347801         8.50   \n",
       "\n",
       "    PUENTES VEHICULARES UND  PUENTES VEHICULARES M2  PUENTES PEATONALES UND  \\\n",
       "20                       10                   24258                       0   \n",
       "21                        0                       0                       0   \n",
       "22                       16                   26811                       0   \n",
       "\n",
       "    PUENTES PEATONALES M2  TUNELES UND  TUNELES KM         ALCANCE  ...  \\\n",
       "20                      0            5      0.9200  Rehabilitación  ...   \n",
       "21                      0            1      8.6000  Rehabilitación  ...   \n",
       "22                      0           15      2.2747  Rehabilitación  ...   \n",
       "\n",
       "   7 - SOCAVACIÓN 8 - ESTRUCTURAS   9 - TÚNELES  10 - URBANISMO Y PAISAJISMO  \\\n",
       "20   6.284023e+07    4.415680e+08  6.644646e+07                          0.0   \n",
       "21   6.472167e+07    4.547886e+08  1.632824e+08                          0.0   \n",
       "22   6.396909e+07    4.495003e+08  1.906902e+08                          0.0   \n",
       "\n",
       "    11 - PREDIAL  12 - IMPACTO AMBIENTAL  13 - CANTIDADES  \\\n",
       "20  1.663940e+07                     0.0              0.0   \n",
       "21  1.713759e+07                     0.0              0.0   \n",
       "22  1.693831e+07                     0.0              0.0   \n",
       "\n",
       "    14 - EVALUACIÓN SOCIOECONÓMICA  15 - OTROS - MANEJO DE REDES  \\\n",
       "20                             0.0                           0.0   \n",
       "21                             0.0                           0.0   \n",
       "22                             0.0                           0.0   \n",
       "\n",
       "    16 - DIRECCIÓN Y COORDINACIÓN  \n",
       "20                   2.006346e+08  \n",
       "21                   2.066416e+08  \n",
       "22                   2.042388e+08  \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vp[df_vp['9 - TÚNELES']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1032ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, target: str, method='ensemble', contamination=0.1, voting_threshold=0.5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Advanced outlier detection using multiple methods.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe\n",
    "    target : str\n",
    "        Target column name\n",
    "    method : str\n",
    "        'ensemble' (default): Combines multiple methods with voting\n",
    "        'isolation_forest': Uses Isolation Forest only\n",
    "        'lof': Uses Local Outlier Factor only\n",
    "        'robust_statistical': Uses Modified Z-score with MAD\n",
    "        'all_strict': All methods must agree (strictest)\n",
    "    contamination : float\n",
    "        Expected proportion of outliers (0.05-0.2 typical)\n",
    "    voting_threshold : float\n",
    "        For ensemble method, fraction of methods that must flag as outlier (0.5 = majority)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Cleaned dataframe without outliers\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove zero values first (domain-specific)\n",
    "    df_nonzero = df[df[target] != 0].copy()\n",
    "    \n",
    "    if len(df_nonzero) < 10:\n",
    "        print(f\"Warning: Only {len(df_nonzero)} samples. Skipping outlier detection.\")\n",
    "        return df_nonzero\n",
    "    \n",
    "    # Prepare features: numerical columns + target\n",
    "    numerical_cols = df_nonzero.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Scale features for better outlier detection\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df_nonzero[numerical_cols])\n",
    "    \n",
    "    # Initialize outlier flags\n",
    "    outlier_flags = {}\n",
    "    \n",
    "    # Method 1: Isolation Forest (excellent for high-dimensional data)\n",
    "    if method in ['ensemble', 'isolation_forest', 'all_strict']:\n",
    "        iso_forest = IsolationForest(\n",
    "            contamination=contamination,\n",
    "            random_state=42,\n",
    "            n_estimators=200,\n",
    "            max_samples='auto',\n",
    "            bootstrap=True\n",
    "        )\n",
    "        iso_predictions = iso_forest.fit_predict(X_scaled)\n",
    "        outlier_flags['isolation_forest'] = (iso_predictions == -1)\n",
    "        \n",
    "    # Method 2: Local Outlier Factor (density-based, good for local anomalies)\n",
    "    if method in ['ensemble', 'lof', 'all_strict']:\n",
    "        n_neighbors = min(20, len(df_nonzero) - 1)\n",
    "        lof = LocalOutlierFactor(\n",
    "            n_neighbors=n_neighbors,\n",
    "            contamination=contamination\n",
    "        )\n",
    "        lof_predictions = lof.fit_predict(X_scaled)\n",
    "        outlier_flags['lof'] = (lof_predictions == -1)\n",
    "    \n",
    "    # Method 3: Modified Z-score with MAD (robust to outliers themselves)\n",
    "    if method in ['ensemble', 'robust_statistical', 'all_strict']:\n",
    "        target_values = df_nonzero[target].values\n",
    "        median = np.median(target_values)\n",
    "        mad = np.median(np.abs(target_values - median))\n",
    "        \n",
    "        # Modified Z-score (more robust than standard Z-score)\n",
    "        if mad != 0:\n",
    "            modified_z_scores = 0.6745 * (target_values - median) / mad\n",
    "            # Threshold of 3.5 is standard for modified Z-score\n",
    "            outlier_flags['robust_statistical'] = np.abs(modified_z_scores) > 3.5\n",
    "        else:\n",
    "            outlier_flags['robust_statistical'] = np.zeros(len(df_nonzero), dtype=bool)\n",
    "    \n",
    "    # Method 4: Multivariate Z-score on target (additional check)\n",
    "    if method in ['ensemble', 'all_strict']:\n",
    "        target_scaled = scaler.fit_transform(df_nonzero[[target]])\n",
    "        outlier_flags['z_score'] = np.abs(target_scaled.flatten()) > 3\n",
    "    \n",
    "    # Combine methods based on selected strategy\n",
    "    if method == 'ensemble':\n",
    "        # Voting: flag as outlier if voting_threshold fraction of methods agree\n",
    "        outlier_matrix = np.column_stack(list(outlier_flags.values()))\n",
    "        votes = outlier_matrix.sum(axis=1)\n",
    "        is_outlier = votes >= (len(outlier_flags) * voting_threshold)\n",
    "        \n",
    "    elif method == 'all_strict':\n",
    "        # All methods must agree (most conservative)\n",
    "        outlier_matrix = np.column_stack(list(outlier_flags.values()))\n",
    "        is_outlier = outlier_matrix.all(axis=1)\n",
    "        \n",
    "    elif method in ['isolation_forest', 'lof', 'robust_statistical']:\n",
    "        # Single method\n",
    "        is_outlier = outlier_flags[method]\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    # Filter out outliers\n",
    "    df_clean = df_nonzero[~is_outlier].copy()\n",
    "    \n",
    "    # Report\n",
    "    n_outliers = is_outlier.sum()\n",
    "    pct_removed = (n_outliers / len(df_nonzero)) * 100\n",
    "    print(f\"  → Removed {n_outliers}/{len(df_nonzero)} outliers ({pct_removed:.1f}%) using {method}\")\n",
    "    \n",
    "    if method == 'ensemble' and len(outlier_flags) > 1:\n",
    "        for flag_name, flags in outlier_flags.items():\n",
    "            print(f\"     • {flag_name}: {flags.sum()} outliers\")\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f77180a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(df_real, predictor1, predictor2, target, n_synthetic=20):\n",
    "    X_real = df_real[[predictor1, predictor2]].values\n",
    "    y_real = df_real[target].values\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    X_synthetic = []\n",
    "    y_synthetic = []\n",
    "    \n",
    "    for _ in range(n_synthetic):\n",
    "        idx1, idx2 = np.random.choice(len(df_real), 2, replace=False)\n",
    "        alpha = np.random.beta(2, 2)\n",
    "        \n",
    "        x_new = alpha * X_real[idx1] + (1 - alpha) * X_real[idx2]\n",
    "        x_new *= np.random.uniform(0.99, 1.01, size=2)\n",
    "        \n",
    "        ratio1 = x_new[0] / X_real[idx1, 0] if X_real[idx1, 0] != 0 else 1\n",
    "        ratio2 = x_new[1] / X_real[idx1, 1] if X_real[idx1, 1] != 0 else 1\n",
    "        y_new = y_real[idx1] * (ratio1**0.6) * (ratio2**0.4)\n",
    "        y_new *= np.random.uniform(0.99, 1.01)\n",
    "        \n",
    "        X_synthetic.append(x_new)\n",
    "        y_synthetic.append(y_new)\n",
    "    \n",
    "    df_synthetic = pd.DataFrame(X_synthetic, columns=[predictor1, predictor2])\n",
    "    df_synthetic[target] = y_synthetic\n",
    "    \n",
    "    return pd.concat([df_real[[predictor1, predictor2, target]], df_synthetic], ignore_index=True)\n",
    "\n",
    "def train_model_tunnels(df_clean, predictor_name, hue_name, target_name):\n",
    "    predictor1, predictor2 = predictor_name, hue_name\n",
    "    \n",
    "    df_augmented = generate_synthetic_data(df_clean, predictor1, predictor2, target_name, n_synthetic=200)\n",
    "    \n",
    "    X = df_augmented[[predictor1, predictor2]].copy()\n",
    "    X[predictor1 + '_LOG'] = np.log1p(X[predictor1])\n",
    "    X[predictor2 + '_LOG'] = np.log1p(X[predictor2])\n",
    "    y = df_augmented[target_name].astype(float)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    model = TransformedTargetRegressor(regressor=LinearRegression(), func=np.log1p, inverse_func=np.expm1)\n",
    "    model.fit(X_scaled, y)\n",
    "    \n",
    "    X_real = df_clean[[predictor1, predictor2]].copy()\n",
    "    X_real[predictor1 + '_LOG'] = np.log1p(X_real[predictor1])\n",
    "    X_real[predictor2 + '_LOG'] = np.log1p(X_real[predictor2])\n",
    "    y_real = df_clean[target_name].astype(float)\n",
    "    \n",
    "    X_real_scaled = scaler.transform(X_real)\n",
    "    y_pred = model.predict(X_real_scaled)\n",
    "    \n",
    "    r2 = r2_score(y_real, y_pred)\n",
    "    mape = np.mean(np.abs((y_real - y_pred) / y_real)) * 100\n",
    "    \n",
    "    print(f\"\\nR² = {r2:.4f} | MAPE = {mape:.2f}%\")\n",
    "    \n",
    "    class ScaledModel:\n",
    "        def __init__(self, model, scaler, feature_names):\n",
    "            self.model, self.scaler, self.feature_names = model, scaler, feature_names\n",
    "        def predict(self, X_new):\n",
    "            return self.model.predict(self.scaler.transform(X_new[self.feature_names]))\n",
    "    \n",
    "    return X_real, y_real, y_pred, ScaledModel(model, scaler, X.columns.tolist())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c893a966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R² = 0.8339 | MAPE = 9.76%\n",
      "   TUNELES UND  TUNELES KM        Actual     Predicted     Error%\n",
      "0            5      0.9200  6.644646e+07  6.562381e+07   1.238065\n",
      "1            1      8.6000  1.632824e+08  1.275371e+08  21.891687\n",
      "2           15      2.2747  1.906902e+08  2.023911e+08  -6.136095\n"
     ]
    }
   ],
   "source": [
    "def train_and_calculate_metrics_tunnels(df, target_column, predictors):\n",
    "    predictor1, predictor2 = predictors\n",
    "    df_item = df[df[target_column] > 0][[predictor1, predictor2, target_column]].dropna()\n",
    "    \n",
    "    X, y, y_pred, model = train_model_tunnels(df_item, predictor1, predictor2, target_column)\n",
    "    \n",
    "    print(pd.DataFrame({\n",
    "        predictor1: df_item[predictor1].values,\n",
    "        predictor2: df_item[predictor2].values,\n",
    "        'Actual': y.values,\n",
    "        'Predicted': y_pred,\n",
    "        'Error%': ((y.values - y_pred) / y.values * 100)\n",
    "    }))\n",
    "    \n",
    "    return {target_column: {'X': X, 'y': y, 'y_predicted': y_pred, 'trained_model': model}}    \n",
    "\n",
    "target_column = '9 - TÚNELES'\n",
    "predictors = ['TUNELES UND', 'TUNELES KM']\n",
    "\n",
    "df = df_vp[['LONGITUD KM', 'ALCANCE']].join(df_vp.loc[:, '1 - TRANSPORTE':'16 - DIRECCIÓN Y COORDINACIÓN'])\n",
    "df[predictors[0]] = df_vp[predictors[0]]\n",
    "df[predictors[1]] = df_vp[predictors[1]]\n",
    "\n",
    "results = train_and_calculate_metrics_tunnels(df, target_column, predictors)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf1b34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practicum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
